{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#Import PySpark libraries\n",
    "import pyspark\n",
    "import random\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import IntegerType,StringType,LongType,ArrayType\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, udf, approx_count_distinct\n",
    "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col, max as _max, lit\n",
    "from pyspark.sql import functions as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 2.3.2\n",
      "PySpark Version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "#Connect to Spark Cluster\n",
    "conf = SparkConf().setAppName(\"ColumnTypes\").setMaster(\"spark://192.168.56.1:7077\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#Print Spark Version\n",
    "print(\"Spark Version: \" + sc.version)\n",
    "print(\"PySpark Version: \" + pyspark.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _renameDF_Columns(df):\n",
    "    ORIGINAL_COLUMN_NAMES = df.columns\n",
    "    NEW_COLUMN_NAMES = [str(x).upper().strip() for x in ORIGINAL_COLUMN_NAMES]                \n",
    "\n",
    "    for orig, new in zip(ORIGINAL_COLUMN_NAMES,NEW_COLUMN_NAMES):\n",
    "        df=df.withColumnRenamed(orig,new)\n",
    "\n",
    "    return df\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "def intTryParse(value):\n",
    "    value = str(value)\n",
    "    res = re.search('e', str(value), re.IGNORECASE)\n",
    "    if not res:\n",
    "        try:\n",
    "            int(value)\n",
    "            return True\n",
    "\n",
    "        except Exception:\n",
    "            return isFloatWholeNumber(value)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def floatTryParse(value):\n",
    "    value = str(value)\n",
    "    res = re.search('e', str(value), re.IGNORECASE)\n",
    "    if not res:\n",
    "         try:\n",
    "            float(value)\n",
    "            return True\n",
    "         except ValueError:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def isFloatWholeNumber(x):\n",
    "    value = str(x)\n",
    "    try:\n",
    "        fval = float(value)\n",
    "        return fval.is_integer()\n",
    "\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def dateTryParse(s):\n",
    "    s = str(s)\n",
    "    isDate = False\n",
    "\n",
    "    formats = [\"%m/%d/%Y\", \"%Y-%m-%d\", \"%Y-%m-%d %H:%M:%S\"]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            d = datetime.datetime.strptime(s, f)\n",
    "            return True,d\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return isDate, None\n",
    "\n",
    "\n",
    "def isNull(val):\n",
    "    if val==None:\n",
    "        return True\n",
    "    if pd.isnull(val):\n",
    "        return True\n",
    "    if str(val)==\"nan\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "#returns column datatype.. Float, Int, Date or String\n",
    "def getType(x):\n",
    "    isContainsPeriod = False\n",
    "    if str(x).find(\".\") != -1:\n",
    "        isContainsPeriod = True\n",
    "\n",
    "    if intTryParse(x) and not (str(x).startswith('0') and not isContainsPeriod and not (str(x) == '0')):\n",
    "        return \"int\"\n",
    "\n",
    "    if floatTryParse(x) and not (str(x).startswith('0') and not isContainsPeriod):\n",
    "        return \"float\"\n",
    "\n",
    "    isDate, dtConverted =  dateTryParse(str(x))\n",
    "    if isDate:\n",
    "        return \"date\"\n",
    "\n",
    "    return \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=ArrayType(StringType()))\n",
    "def getType_pudf(ser):\n",
    "    converted = [getType(v) for v in ser]\n",
    "    list_set = set(converted) \n",
    "    ltypes = (list(list_set)) \n",
    "\n",
    "    #Determine Length\n",
    "    if \"string\" in ltypes:\n",
    "        lengths = [len(v) for v in ser]\n",
    "        maxLength = max(lengths)\n",
    "    \n",
    "    elif (\"string\" not in ltypes) and (\"date\" not in ltypes):\n",
    "        maxLength = max(ser)\n",
    "    \n",
    "    else:\n",
    "        maxLength = 0\n",
    "    \n",
    "    isNullable = True\n",
    "    \n",
    "    #Determine Nullable\n",
    "    convNull = [isNull(v) for v in ser]\n",
    "    list_set = set(convNull) \n",
    "    nullTypes = (list(list_set)) \n",
    "    \n",
    "    d = {}\n",
    "    d[\"types\"] = ltypes  \n",
    "    d[\"length\"] = maxLength\n",
    "    d[\"nullTypes\"] = nullTypes\n",
    "\n",
    "    return json.dumps(d)\n",
    "\n",
    "\n",
    "def array_to_string_original(my_list):\n",
    "    return '[' + ','.join([str(elem) for elem in my_list]) + ']'\n",
    "\n",
    "def array_to_string(my_list):\n",
    "    #return ','.join([str(elem) for elem in my_list])\n",
    "    return str(my_list)\n",
    "\n",
    "array_to_string_udf = udf(array_to_string, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(REGION='Sub-Saharan Africa', COUNTRY='South Africa', ITEM TYPE='Fruits', SALES CHANNEL='Offline', ORDER PRIORITY='M', ORDER DATE='7/27/2012', ORDER ID='443368995', SHIP DATE='7/28/2012', UNITS SOLD='1593', UNIT PRICE='9.33', UNIT COST='6.92', TOTAL REVENUE='14862.69', TOTAL COST='11023.56', TOTAL PROFIT='3839.13')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read DataSet\n",
    "df = sqlContext.read.csv(\"1500000SalesRecords.csv\",header=True, sep=\",\", inferSchema=False)\n",
    "#Strip Column Names and UpperCase all Columns\n",
    "df = _renameDF_Columns(df)\n",
    "#Print Columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|              REGION|             COUNTRY|           ITEM TYPE|    SALES CHANNEL|ORDER PRIORITY|          ORDER DATE|            ORDER ID|           SHIP DATE|          UNITS SOLD|          UNIT PRICE|           UNIT COST|       TOTAL REVENUE|          TOTAL COST|        TOTAL PROFIT|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[Middle East and ...|[Italy, Slovakia,...|[Beverages, Perso...|[Online, Offline]|  [M, C, H, L]|[7/20/2016, 2/6/2...|[863378036, 44360...|[7/20/2016, 2/6/2...|[2000, 9662, 5080...|[205.70, 255.28, ...|[97.44, 6.92, 364...|[523959.72, 14612...|[4642746.24, 6666...|[11813.82, 166874...|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GET UNIQUE VALUES TO ARRAY IN A DATAFRAME..\n",
    "COLUMN_NAMES = df.columns\n",
    "\n",
    "dfU = df.withColumn(\"Temp\",lit(\"a\"))\n",
    "exprs = [F.collect_set(colName) for colName in COLUMN_NAMES]\n",
    "dfU = dfU.groupby('Temp').agg(*exprs)\n",
    "dfU = dfU.drop(\"Temp\")\n",
    "dfU = dfU.toDF(*COLUMN_NAMES)\n",
    "dfU.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-d36f83c88114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#apply UDF to grouped by data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m dfTypes = dfU.select(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgetType_pudf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-77-d36f83c88114>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#apply UDF to grouped by data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m dfTypes = dfU.select(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgetType_pudf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "#apply UDF to grouped by data\n",
    "dfTypes = dfU.select(\n",
    "    *[getType_pudf(col(col_name)).name(col_name) for col_name in dfU.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to string to allow printing\n",
    "dfTypes_cln = dfTypes.select(\n",
    "    *[array_to_string_udf(col(col_name)).name(col_name) for col_name in dfTypes.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPandas = dfTypes_cln.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dfPandas.to_dict()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = d['TOTAL REVENUE'][0]\n",
    "print(v)\n",
    "jo = json.loads(v)\n",
    "jo['types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in d:\n",
    "    jo = json.loads(d[col][0])\n",
    "    \n",
    "    print(col + \"   \" + str(jo[\"types\"]) + \"   \"  + str(jo[\"length\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTypes_cln.write.csv('type_df.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert to Dictionary\n",
    "new_dict = dfTypes.toPandas().to_dict(orient='list')\n",
    "new_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
